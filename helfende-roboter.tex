% Folien zur TAMS Selbstdarstellung
% 2009.02.24
% 2010.03.08 updates, fixes
%
\documentclass[t]{beamer}
%\usepackage{multimedia}		% for movies, sounds, animations...
%\usepackage[english]{babel}		% new english
%\usepackage[latin1]{inputenc}		% input...
\usepackage[utf8]{inputenc}		% SuSE 10.x default is UTF-8
\usepackage{tabularx}			% local, only for this doc.
%\usepackage[tams, engl, uniWZ, blockBG]{tamsBeamer}
\usepackage[ngerman]{babel}		% new german
\usepackage[tams, blockBG]{tamsBeamer}
%-----------------------------------------------------------------------------
%-- options		------------------------------------------------------
%			tams	|	- TAMS		publication
%			engl		- english strings	[german]
%			uniWZ	|	- uni		watermark
%			tamsWZ	|	- tams+uni	watermark
%			cinacsWZ	- cinacs+uni	watermark
%			secToc	|	- toc repetition at each section
%			secTocA		- -"-, all sections: show
%					  replacement for toc in short docs
%			subsecToc	- toc repetition at each subsection
%			secNum  	- (sub)-section numbering
%			fullstep	- always step through items
%			noFoot		- footline	off
%			noPage		- page numbers	off
%			noAuth		- author	off
%			conference	- footline with \foottitle{...}
%			blockBG	|	- block, example etc. background
%			blockRound	- -"-, rounded+shadow


% colors:     r g b 
% unihh red:  254 0 0
% dark red:   203 0 0
% light gray: 242 242 242
% dark gray:  122 122 120

% fonts definitions			--------------------------------------
% ----------------------------------------------------------------------------
% default: cmss, OT1 fontenc		good with UniHH font "The Sans"
%					-> don't change fonts!
%\usepackage{times}			% other fonts
%\usepackage[T1]{fontenc}		%

% document definitions			--------------------------------------
% ----------------------------------------------------------------------------
%\author[AutorA, AutorB]		% author	-- option: short
% {A.~Autor\inst{1} \and B.~Autor\inst{2}}%		-- option: \inst{...}
% style option: [tams] predefines institute...
% or define \institute{...}
%					% \inst{...} for different institutions
%\institute[Universities A and B]	% institution	-- option: short
%{ \inst{1}%
%  University of A\\
%  Department of A
%  \and
%  \inst{2}%
%  University of B\\
%  Department of B}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title[Helfende Roboter]{Helfende Roboter\\
  %Eine kurze Einführung in die Service-Robotik
  %Service-Robotik für alle?
  {\small Die Perspektive der Service-Robotik}
}
\author[N.\,Hendrich, A.\,Mäder]{Norman Hendrich, Andreas Mäder}
%Prof. Dr. Jianwei Zhang\\
%Norman Hendrich, Denis Klimentjew
\institute{%
Universität Hamburg\\
MIN Fakultät, Fachbereich Informatik\\
Technische Aspekte Multimodaler Systeme\\
Vogt-Kölln-Str. 30, D-22527 Hamburg\\
\{hendrich,maeder\}@informatik.uni-hamburg.de}
\date[29/10/2011]{Vierte Nacht des Wissens, Hamburg, 29.~Okt.~2011}


\def\quelle#1{{\tiny \makebox(0,0){}\vfill\hfill #1}}
\def\ii{\item[]}


\begin{document}

\frame{\titlepage}


%\begin{frame}
%  \frametitle{\tocName}
%  \tableofcontents
%\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{~}


\begin{frame}
\frametitle{Arbeitsbereich TAMS: die Menschen}
%\includegraphics[width=11cm]{images/group2007.jpg}\\
{\tiny
Universität Hamburg\\
Fakultät für Mathematik, Informatik und Naturwissenschaften\\
Fachbereich Informatik, Technische Grundlagen Multimodaler Systeme (TAMS)\\
Vogt-Kölln-Straße 30, D-22527 Hamburg\\
Tel.:~+49~40~-~42883-2430\\
email: tams-info@informatik.uni-hamburg.de\\
http://tams.informatik.uni-hamburg.de/

}
\end{frame}


\begin{frame}
\frametitle{Arbeitsbereich TAMS: und unsere Roboter}
%\frametitle{\dots und unsere Roboter}
%\picturegraphics{60}{-55}{width=45mm}{images/robots.jpg}%
\begin{itemize}
\item TASER
\item Shadow-hand
\item Hoap-2
\item Aibo
\item Pioneer
\item Lego Mindstorms
\item Modular-Robots GZ-1
\item SkyCleaner
\ii
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Was ist ein "`Roboter"'?}
%\picturegraphics{92}{-30}{width=22mm}{images/abb01IRB-6640-615-900.jpg}
%\picturegraphics{92}{-55}{width=22mm}{images/img125.png}
eine vielseitige Maschine 
\begin{itemize}
\item zur Herstellung oder Bearbeitung von Dingen
\item mit Armen und Greifern oder Händen
\item Steuerung durch einen Computer
\ii
\end{itemize}
Industrie-Roboter werden in der Fabrik fest eingebaut
\begin{itemize}
\item für eine bestimmte Aufgabe eingerichtet
\item z.B. Schweißen oder Schrauben
\item feste Bewegungsabläufe
\item können bei Bedarf neu programmiert werden
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Industrie-Roboter: Schweißen von Autos}
%\includegraphics[width=85mm]{images/industrieroboter-volvo.jpg}%
\end{frame}




\begin{frame}
\frametitle{Aber was ist ein "`Service-Roboter"'?}
%\picturegraphics{90}{-20}{width=20mm}{images/Bild_Robotik_klein.jpg}%
%\picturegraphics{90}{-55}{width=20mm}{images/care-o-bot-3.jpg}%
ein Roboter, der keine Dinge herstellt
\begin{itemize}
\item zur Unterstützung von Menschen
\item als Haushaltshilfe, zum Spielen, \dots
\item nicht fest montiert, sondern beweglich
\item Beine oder Fahrgestell mit Rädern
\item[]
\item Steuerung durch einen Computer
\item Kameras und Sensoren zur Erkennung der Umwelt
\item Planung von Aktionen
\item Greifen und Manipulation von Gegenständen
\item Mensch-Roboter Schnittstelle und Interaktion
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Unser Service-Roboter: "`TASER"'}
%\framesubtitle{"`TAMS-SErvice-Roboter"'}
%\picturegraphics{80}{-50}{width=29mm}{images/taser-2arm.jpg}%
\begin{itemize}
\item Fahrgestell mit Rädern (Neobotix)
\item ein oder zwei Roboterarme (PA-10)
\item Hände mit je drei Fingern (Barrett)
\item diverse Kameras, Laserscanner
\item Mikrophon, Sprachausgabe
\item Linux-PC zur Steuerung
\item Batteriebetrieb, 3-4 Stunden
\ii
\item Beispiele und Videos kommen gleich 
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{"`Hol mir eine Tasse Kaffee"'}
\begin{itemize}
\item die Standardaufgabe der Service-Robotik
\item klingt eigentlich ganz einfach, oder?
\item[]
\end{itemize}
Aber:
\begin{itemize}
\item wer hat den Auftrag erteilt?
\item was ist das, eine Tasse Kaffee?
\item wo bekommt man Kaffee, wohin soll man die Tasse bringen?
\item wie greift und bringt man eine Tasse?
\item wie vermeidet man Hindernisse und Unfälle?
\end{itemize}
\end{frame}


\begin{frame}
%\frametitle{Wie redet man mit einem Roboter?}
\frametitle{Wie bekommt der Roboter seine Aufgaben? }
Viele Möglichkeiten der "`human-robot interaction"':
\begin{itemize}
\item Sprache            \hfill ("`bring mir einen Kaffee"')
\item Fernsteuerung      \hfill (Wiimote-Demo)
\item Eintippen von Befehlen   
\item vorprogrammierte Aktionen \hfill (z.B. Zeitplan/Kalender)
\item[]
\end{itemize}
Noch besser:
\begin{itemize}
\item Demonstration der Aufgabe und der Roboter lernt,\\
      was er tun soll 
\item der Roboter beobachtet, und lernt was er tun könnte
\end{itemize}
\end{frame}




\begin{frame}
\frametitle{Wo ist der Roboter?}
Ein beweglicher Roboter muss wissen, wo er sich gerade befindet.
Das nennt man \textbf{Lokalisierung}:
\begin{itemize}
\item Navigationssysteme                        \hfill (z.B. GPS-Satelliten)
\item Auswertung von Kamerabildern 
\item Laserscanner messen Entfernungen                         \hfill (Demo)
\item Ultraschall                                              \hfill (Demo)
\item Stoßstangen und Taster
\ii
\item Erkennung von Hindernissen und Wänden                    \hfill (Demo)
\item Erkennung von Landmarken
\item Vergleich mit Landkarte/Grussriss der Wohnung
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Wo ist der Roboter? Beispiel Pioneer-2}
%\includegraphics[width=70mm]{images/stage-001-0000.jpg}
\begin{itemize}
\item Beispieldaten, Roboter ist in Bildmitte \hfill (Demo)
\item Laserscanner (blau) und Ultraschall (beige)
\item Achtung: die Daten passen nicht perfekt zusammen
\item Aufgabe: Hindernisse erkennen, Wände und Objekte erahnen
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Wo bekommt man den Kaffee?}
Der Roboter braucht eine \textbf{Landkarte} seiner Umgebung:
\begin{itemize}
\item Wohnzimmer, Kinderzimmer, Flur, \dots                 \hfill (Küche)
\item Möbel, Einrichtung                          \hfill (Geschirrschrank)    
\item wichtige Gegenstände                          \hfill (Kaffemaschine)
\item Türen und andere bewegliche Dinge
\ii
\end{itemize}
\begin{itemize}
\item vorprogrammierte Karten                \hfill (Stadtplan, Grundriss)
\item selbsterstellte Karten                             \hfill ("`SLAM"')
\item Erkennen von Hindernissen              \hfill (z.B. Sofa verschoben)
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Wie findet der Roboter zum Ziel?}
Der Roboter braucht eine Regel zur \textbf{Wegplanung} (Navigation):
\begin{itemize}
\item wo ist der Roboter jetzt?
\item wo ist das Ziel?
\item suche einen möglichst kurzen Weg auf der Landkarte
\ii
\item das Problem gilt als gelöst (in 2D)
\item es gibt gute Standardverfahren
\item Beispiele: Auto-Navigation, HVV-Geofox, usw.
\ii
\item beachte Türen und Hindernisse
\item es gibt brauchbare Planungsverfahren
\ii 
\item aber: viel schwieriger in 3D, bisher ungelöst
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Beispiel: Staubsauger-Roboter}
%\picturegraphics{88}{-15}{width=25mm}{images/roomba-560.jpg}%
die ersten Service-Roboter, die man kaufen kann
\begin{itemize}
\item nur genau eine Funktion: Staubsaugen
\item Vorteil: man muss sich nicht `drum kümmern
\ii
\item relativ klein, daher wenig Saugkraft
\item Probleme mit Treppen, Teppichen, Tierhaaren\dots
\item automatische Ladestationen, Absperrzonen
\item wenig Intelligenz, aber einige interessante Tricks
\item insbesondere: unterschiedliche Wegplanung
\item \dots
\end{itemize}
\quelle{%
www.heise.de/ct/artikel/Saubermaenner-24-Saugroboter-von-200-bis-1150-Euro-im-Test-1321903.html}
\end{frame}


\begin{frame}
\frametitle{Staubsauger-Roboter: Viele Wege führen zum Ziel\dots}
%\picturegraphics{55}{-25}{width=50mm}{images/ct-roomba.png}%
%\picturegraphics{0}{-55}{width=50mm}{images/ct-kornkreise.png}%
%\picturegraphics{55}{-55}{width=50mm}{images/ct-systematisch.png}%
\vspace*{-5mm}
\begin{itemize}
\item zufällige Wege
\item kreisförmige Pfade
\item systematisches Gitter
\item \dots
\end{itemize}
%\quelle{%
%www.heise.de/ct/artikel/Saubermaenner-24-Saugroboter-von-200-bis-1150-Euro-im-Test-1321903.html}
\end{frame}


\begin{frame}
\frametitle{Was ist das, eine "`Tasse Kaffee"'?}
Wie erkennt der Roboter Objekte?
\begin{itemize}
\item heutige Kameras liefern tolle Bilder
\item aber die Auswertung der Bilder ist schwierig
\begin{itemize}
 \item Trennung von Objekt und Hintergrund
 \item Anpassung an unterschiedliche Beleuchtung
 \item Verdeckung, Doppeldeutigkeiten
 \item Objekt-Kategorien (z.B. "`Tasse"')
 \item sehr zeitaufwendig 
\end{itemize}
\ii
\item alternative Sensoren, z.B. Laserscanner  \hfill (Pioneer-Demo) 
\item neueste Entwicklung: 3D-Kameras \hfill (Kinect-Demo)
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Objekterkennung: Punktwolken und Tiefenkarte}
%\picturegraphics{35}{-45}{height=49mm}{images/datenLRFSnap00.png}%
%\picturegraphics{-5}{-55}{width=49mm}{images/denis-fusion.png}%
\end{frame}


\begin{frame}
\frametitle{Kann ein Roboter lernen?}
\begin{itemize}
\item na klar!  Siehe auch den vorherigen Vortrag!
\ii
\end{itemize}
Es gibt viele verschiedene Ideen:
\begin{itemize}
\item Neuronale Netze als Nachbau des menschlichen Gehirns 
\item Selbst-organisierende Karten
\item Entscheidungsbäume
\item Verstärkungslernen für Aktionen in unbekannten Umgebungen
\item und vieles mehr\dots
\ii
\item "`lifelong-learning"' gilt auch für Roboter
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Beispiel: Imitation und Lernen von Handbewegungen}
%\includegraphics[width=8cm]{images/markus-hand-tracking.png}
\begin{itemize}
\item Optisches Tracking der Hand mit "`active contours"'
\item Selbstorganisierende Karte zum Lernen der Bewegung
\end{itemize}
\quelle{Hüser et. al, HCII 2007, LNCS 4555, pp. 888–897 (2007)}
\end{frame}





\begin{frame}
\frametitle{Greifen und Manipulation}
%\picturegraphics{88}{-40}{width=25mm}{images/shadow-with-rubik.jpg}\\
\vspace*{-5mm}
Ein besonders schwieriges Thema:
\begin{itemize}
\item Industrie-Roboter arbeiten mit festen Werkzeugen
\item und genau bekannten Werkstücken
\item typisch sind einfache Greifer (wie eine Zange)
\ii
\end{itemize}
Service-Roboter sollen alles greifen können:
\begin{itemize}
\item beliebig geformte oder sogar bewegliche Objekte
\item Objekt mit mehreren Fingern berühren
\item Kraft der Finger regeln, damit Objekt nicht rutscht
\item unterschiedliche Griffposition, je nach Aufgabe
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Greifen lernen?!}
%\picturegraphics{85}{-55}{width=29mm}{images/glbottle-handover-free.jpg}\\
%\picturegraphics{85}{-20}{width=29mm}{images/glmug-top-handover.jpg}\\
\vspace*{-9mm}
Unser {\em zgrasp}-Simulator:
\begin{itemize}
\item berücksichtigt die Aufgabe ("`grasp semantics"'):\\
      Anheben, Einfüllen/Ausleeren, Weitergeben, usw.
\item arbeitet mit 3D-Modellen realer Objekte
\item Lernen aus bisherigen Erfahrungen 
\item Tricks zum schnelleren Lernen \\
      (z.B. "`experience replay"')
\item[]
\item Griffe mit dem Roboter ausprobieren
\item Tests mit der 3-Finger Barrett-Hand
\item Video: Greifen
\end{itemize}
%\quelle{Baier-Löwenstein\,\&\,Zhang, 
%{\em Reusability-based Semantics for Grasp Evaluation \dots},  
%(ROBIO 2006)}
\end{frame}


\begin{frame}
\frametitle{Projekt HANDLE: Manipulation}
%\picturegraphics{85}{-50}{width=29mm}{images/shadow-with-egg.jpg}\\
%\picturegraphics{85}{-15}{width=29mm}{images/shadow-with-bottle.jpg}\\
\vspace*{-8mm}%
\begin{itemize}
\item Analyse menschlicher Greifbewegungen
\item inklusive "`In-Hand"' Manipulation
\item[]
\item Datenhandschuh
\item spezielle "`sensing objects"'
\item Kategorisierung der Bewegungen
\item[]
\item Kontext-Modellierung ("`object affordances"')
\item "`motor-babbling"' zum Lernen von Bewegungen
\item Shadow C5 Roboterhand 
\item 20~Freiheitsgrade, flexible "`Luftmuskeln"'
\end{itemize}
%\quelle{www.handleproject.eu}
\end{frame}


\begin{frame}
\frametitle{Shadow C5 Roboterhand}
\begin{itemize}
\item Cyberglove-Datenhandschuh, mit Kalibrierung
\item Teleoperation für In-Hand-Manipulation
\end{itemize}
%\includegraphics[width=80mm]{images/lorenzo-rotating-blocks.png}
\end{frame}


\begin{frame}
\frametitle{Aktuelles Projekt: HYFLAM}
{\em Handling of hazardous material using a dexterous robot hand}
\begin{itemize}
\item Experiment im Rahmen des EU-Projekts ECHORD (2.~Phase)
\item zusammen mit Partnern Shadow-Robot und HPA
\item[]
\item Manipulation von Ampullen und Probenröhrchen
\item Handhabung von Eiern für "`incubation"'
\item als Ersatz für traditionelle "`Glove-Box"'-Geräte
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Wie spielt das alles zusammen?}
Wir brauchen spezielle Software (-programme), um alle Teile
des Roboters anzusteuern:
\begin{itemize}
\item die Geräte: Kameras, Sensoren, Arm, Hand
\item die Grundfunktionen zum Fahren
\item Zugriff auf die Landkarte und Wegplanung
\item die Interaktion mit Menschen
\item für das Lernen und Planen von Aktionen
\item \dots
\ii
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Software-Architektur bei TASER}
%\picturegraphics{85}{-50}{width=29mm}{images/taser-2arm.jpg}%
\vspace*{-5mm}
\begin{itemize}
\item Client/Server-Architektur
\item verteilte Steuerung, Aufteilung auf\\
      mehrere Computer möglich
\item modularer Aufbau der Software
      \begin{itemize}
      \item Fahren des Roboters, Pfad-Planung
      \item Lokalisierung, Erkennung von "`Landmarken"'
      \item Verarbeitung der Sensordaten
      \item Bewegungen des Arms und der Hand
      \item Mensch-Maschine Interaktion
      \item Visualisierung
      \item Planer
      \end{itemize}
\item Video: Tür-öffnen
\end{itemize}
%\quelle{Westhoff, Stanek, et.al., {\em A flexible framework for task-oriented programming of service robots} (Robotik 2004)}
\end{frame}


\begin{frame}
\frametitle{Software-Komponenten unseres Service-Roboters}
%\includegraphics[width=110mm]{images/roblet-arch.png}\\
Hardware - Gerätereiber - Abstraktion - Netzwerk - Applikationen
%\begin{itemize}
%\item 
%\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Plan-basierte Steuerung des Roboters}
%\picturegraphics{46}{-25}{height=20mm}{images/hierarchy-example.png}%
%\vspace*{-5mm}
Zwei Schichten:
\begin{itemize}
\item symbolische Ebene (Planer)
\item "`reaktive"' Ebene (Reflexe)
      \\~
\item PDDL Beschreibung
\item JSHOP2 Planer
\item Bibliothek mit {\em atomaren} Aktionen
\item "`Symbol grounding"'
\item Aktive Wahrnehmung und Exploration der Umgebung
\end{itemize}
\quelle{Weser\,et.al., 
{\em Fuzzy Multisensor Fusion for Autonomous Proactive Robot Perception}, 
(FUZZ/WCCI 2008)}
%\quelle{Weser\,et.al., 
%HTN Robot Planning in Partially Observable Dynamic Environments,
%(ICRA 2010)}
\end{frame}


\begin{frame}
\frametitle{Plan-Anpassung}
%\picturegraphics{-5}{-55}{height=59mm}{images/screen-replanning.png}%
%\picturegraphics{50}{-52}{height=54mm}{images/screen-taser-grasps.jpg}%
\strut
\vspace*{50mm}
\quelle{Weser\,et.al., 
HTN Robot Planning in Partially Observable Dynamic Environments (ICRA 2010)}
\end{frame}


\begin{frame}
\frametitle{Tele-Operation mit haptischer Schnittstelle}
%\framesubtitle{Phantom and Barrett-hand: tele-operation setup}
%\includegraphics[height=59mm]{images/teleoperation-jan-bruder.png}~
%\includegraphics[height=39mm]{images/teleoperation-demo-small.jpg}
\end{frame}


%\begin{frame}
%\frametitle{CINACS: PhD-Thesis}
%%{\em ''Cross-Modal Enhanced Memory for Mobile Service Robots''}\\
%\ \\
%Endow a service robot with an hierarchical
%multi-modal memory systems that..
%\begin{itemize}
%\item is grounded in physical action and sensing
%modalities
%\item enables a planner to improve it capabilities
%\item provides advanced reasoning capabilities
%\item dynamically integrate different modalities
%into abstract robot skills
%\end{itemize}
%\end{frame}
%

%\begin{frame}
%\frametitle{Enhanced memory architecture}
%\includegraphics[height=55mm]{images/memory-architecture-dominik.pdf}
%\end{frame}



\begin{frame}
\frametitle{Zusammenfassung: Service-Roboter}
\begin{itemize}
\item Grundidee
\item mobile autonome Roboter
\item Interaktion mit Menschen
\ii
\item Lokalisierung und Wegplanung
\item Greifen und Manipulation
\item Planen und Lernen von Aktionen 
\ii

\item großes Potential
\item genug Forschungsthemen für die nächsten 20 Jahre
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Danke für Ihr Interesse!}
\begin{itemize}
\item Fragen?
\item Diskussion!
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Backup-Folien}
\begin{itemize}
\item Hintergrundinformationen
\item weitere Details
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Industrie-Roboter: Statistik}
%\picturegraphics{-8}{-55}{height=49mm}{images/kuka-regionen.png}%
%\picturegraphics{50}{-55}{height=49mm}{images/kuka-branchen.png}%
\vspace*{-5mm}
\strut
\begin{itemize}
\item weltweit ca. 1,1\,Million Roboter im Einsatz
\ii
\end{itemize}
\vspace*{45mm}
\quelle{(KuKA AG, 2008)}
\end{frame}


\begin{frame}
\frametitle{Service-Roboter: privater Einsatz}
%\includegraphics[width=99mm]{images/IFR-sold-units-2009.png}
\quelle{www.ifr.org/service-robots/statistics/}
\end{frame}


\begin{frame}
\frametitle{Service-Roboter: professioneller Einsatz}
%\includegraphics[width=99mm]{images/IFR-2009-service-robots.png}
\quelle{www.ifr.org/service-robots/statistics/}
\end{frame}




\begin{frame}
\frametitle{Service-Roboter: Galerie}
\framesubtitle{DESIRE, Rollin' Justin, PR2, AILA, Romeo, Omnirob}
%\picturegraphics{-1}{-25}{height=29mm}{images/DESIRE-2009.jpg}
%\picturegraphics{25}{-25}{height=29mm}{images/justin-02-300.jpg}
%\picturegraphics{50}{-25}{height=29mm}{images/pr2-calls-the-pool-shots.jpg}
%\picturegraphics{-1}{-55}{height=29mm}{images/AILA-DFKI-glamor-1.jpg}
%\picturegraphics{25}{-55}{height=29mm}{images/AILA.jpg}
%\picturegraphics{50}{-55}{height=29mm}{images/romeo.jpg}
%\picturegraphics{72}{-55}{height=29mm}{images/kuka-omnirob.png}
\end{frame}






\end{document}

